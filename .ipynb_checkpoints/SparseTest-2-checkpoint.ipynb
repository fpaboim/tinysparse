{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4309590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRY GPU\n",
      "DEVICE:GPU\n"
     ]
    }
   ],
   "source": [
    "from tinygrad.densetensor import DenseTensor\n",
    "from tinygrad.sparsetensor import SparseTensor\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb532fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = np.random.randn(1,3).astype(np.float32)\n",
    "x2_init = np.random.randn(3).astype(np.float32)\n",
    "U_init = np.random.randn(3,3).astype(np.float32)\n",
    "V_init = np.random.randn(3,3).astype(np.float32)\n",
    "W_init = np.random.randn(3,3).astype(np.float32)\n",
    "m_init = np.random.randn(1,3).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb8a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense shape grad; (1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.937291], dtype=float32),\n",
       " <DenseTensor <GPUBuffer with shape (1, 3)> with grad <GPUBuffer with shape (1, 3)>>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = DenseTensor(x_init)\n",
    "W = DenseTensor(W_init)\n",
    "m = DenseTensor(m_init)\n",
    "out = x.dot(W).relu()\n",
    "out = out.logsoftmax()\n",
    "out = out.mul(m).add(m).sum()\n",
    "out.backward()\n",
    "\n",
    "out.cpu().data, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b0ba5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15740097 -1.49643     0.8047216 ]\n",
      " [ 0.09809071  0.9113054  -1.217771  ]\n",
      " [ 0.96030104  2.6248736  -0.3236745 ]]\n",
      "ELLW: 3\n",
      "ELLW: 3\n",
      "dense shape grad;aval, xval: 0.16,0.11:0-0 \n",
      "aval, xval: 0.10,0.11:0-3 \n",
      "aval, xval: 0.96,0.11:0-6 \n",
      "aval, xval: -1.50,-0.35:1-1 \n",
      "aval, xval: 0.91,-0.35:1-4 \n",
      "aval, xval: 2.62,-0.35:1-7 \n",
      "aval, xval: 0.80,0.52:2-2 \n",
      "aval, xval: -1.22,0.52:2-5 \n",
      "aval, xval: -0.32,0.52:2-8 \n",
      "SUM/NNZ: 0.96 3 \n",
      "SUM/NNZ: -0.94 3 \n",
      "SUM/NNZ: -0.99 3 \n",
      " (1,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31177/814277375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HD2/ML/tinygrad/tinygrad/densetensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mProfileOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HD2/ML/tinygrad/tinygrad/ops_gpusparse.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0mgrad_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcl_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m     \u001b[0mgrad_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcl_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HD2/ML/tinygrad/tinygrad/ops_gpusparse.py\u001b[0m in \u001b[0;36mbuffer_new\u001b[0;34m(ctx, shape, zero)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuffer_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mGPUBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhostbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mzero\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuffer_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/HD2/ML/tinygrad/tinygrad/densetensor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, hostbuf, dtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGPUBuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhostbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhostbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcl\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPUBuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       cl.Buffer(cl_ctx, cl.mem_flags.READ_WRITE | (cl.mem_flags.COPY_HOST_PTR if hostbuf is not None else 0), 4*np.prod(shape),\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "x2 = DenseTensor(x2_init)#.gpu()\n",
    "W = SparseTensor(W_init)\n",
    "out = W.dot(x2).relu().sum()\n",
    "\n",
    "out.backward()\n",
    "\n",
    "out.cpu().data, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "from time import time\n",
    "import numpy\n",
    "\n",
    "block_size = 16\n",
    "\n",
    "ctx = cl.create_some_context()\n",
    "\n",
    "for dev in ctx.devices:\n",
    "    assert dev.local_mem_size > 0\n",
    "\n",
    "queue = cl.CommandQueue(ctx,\n",
    "        properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "\n",
    "#queue = cl.CommandQueue(ctx)\n",
    "\n",
    "if False:\n",
    "    a_height = 4096\n",
    "    #a_height = 1024\n",
    "    a_width = 2048\n",
    "    #a_width = 256\n",
    "    #b_height == a_width\n",
    "    b_width = a_height\n",
    "\n",
    "elif False:\n",
    "    # like PyCUDA\n",
    "    a_height = 2516\n",
    "    a_width = 1472\n",
    "    b_height = a_width\n",
    "    b_width = 2144\n",
    "\n",
    "else:\n",
    "    # CL SDK\n",
    "    a_width = 128*block_size\n",
    "    a_height = 128*block_size\n",
    "    b_width = 50*block_size\n",
    "    b_height = a_width\n",
    "\n",
    "c_width = b_width\n",
    "c_height = a_height\n",
    "\n",
    "h_a = numpy.random.rand(a_height, a_width).astype(numpy.float32)\n",
    "h_b = numpy.random.rand(b_height, b_width).astype(numpy.float32)\n",
    "h_c = numpy.empty((c_height, c_width)).astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel_params = {\"block_size\": block_size,\n",
    "        \"w_a\":a_width, \"h_a\":a_height, \"w_b\":b_width}\n",
    "\n",
    "prg = cl.Program(ctx, KERNEL_CODE % kernel_params,\n",
    "        ).build(options=\"-cl-mad-enable -cl-fast-relaxed-math\")\n",
    "kernel = prg.matrixMul\n",
    "#print prg.binaries[0]\n",
    "\n",
    "assert a_width % block_size == 0\n",
    "assert a_height % block_size == 0\n",
    "assert b_width % block_size == 0\n",
    "\n",
    "# transfer host -> device -----------------------------------------------------\n",
    "mf = cl.mem_flags\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "d_a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=h_a)\n",
    "d_b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=h_b)\n",
    "d_c_buf = cl.Buffer(ctx, mf.WRITE_ONLY, size=h_c.nbytes)\n",
    "\n",
    "push_time = time()-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup ----------------------------------------------------------------------\n",
    "for i in range(5):\n",
    "    event = kernel(queue, h_c.shape, (block_size, block_size), \n",
    "            d_c_buf, d_a_buf, d_b_buf)\n",
    "    event.wait()\n",
    "\n",
    "queue.finish()\n",
    "\n",
    "# actual benchmark ------------------------------------------------------------\n",
    "t1 = time()\n",
    "\n",
    "count = 20\n",
    "for i in range(count):\n",
    "    event = kernel(queue, h_c.shape, (block_size, block_size),\n",
    "            d_c_buf, d_a_buf, d_b_buf)\n",
    "\n",
    "event.wait()\n",
    "\n",
    "gpu_time = (time()-t1)/count\n",
    "\n",
    "# transfer device -> host -----------------------------------------------------\n",
    "t1 = time()\n",
    "cl.enqueue_copy(queue, d_c_buf, h_c)#.wait()\n",
    "pull_time = time()-t1\n",
    "\n",
    "# timing output ---------------------------------------------------------------\n",
    "gpu_total_time = gpu_time+push_time+pull_time\n",
    "\n",
    "print(\"GPU push+compute+pull total [s]:\", gpu_total_time)\n",
    "print(\"GPU push [s]:\", push_time)\n",
    "print(\"GPU pull [s]:\", pull_time)\n",
    "print(\"GPU compute (host-timed) [s]:\", gpu_time)\n",
    "print(\"GPU compute (event-timed) [s]: \", (event.profile.end-event.profile.start)*1e-9)\n",
    "\n",
    "gflop = h_c.size * (a_width * 2.) / (1000**3.)\n",
    "gflops = gflop / gpu_time\n",
    "\n",
    "print(\"GFlops/s:\", gflops)\n",
    "\n",
    "# cpu comparison --------------------------------------------------------------\n",
    "t1 = time()\n",
    "h_c_cpu = numpy.dot(h_a,h_b)\n",
    "cpu_time = time()-t1\n",
    "\n",
    "print(\"---------------------------\")\n",
    "print(\"GPU==CPU:\",numpy.allclose(h_c, h_c_cpu))\n",
    "print(\"CPU time (s)\", cpu_time)\n",
    "\n",
    "print(\"GPU speedup (with transfer): \", cpu_time/gpu_total_time)\n",
    "print(\"GPU speedup (without transfer): \", cpu_time/gpu_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb173b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyopencl as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1 = 4\n",
    "dim2 = 8\n",
    "dim3 = 1\n",
    "\n",
    "sparsity = 0.2\n",
    "\n",
    "a = np.zeros((dim1,dim2))\n",
    "b = np.random.rand(dim2,dim3).flatten().astype(np.float32)\n",
    "\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sparse(mat, sparsity=0.1):\n",
    "    indices = np.array(range(mat.shape[1]))\n",
    "    nrows = int(mat.shape[1]*sparsity)\n",
    "    for row in range(mat.shape[0]):\n",
    "        lim = nrows #+ int(np.random.random()*3)\n",
    "        mat[row][np.random.permutation(indices)[:lim]] = np.random.random(lim)\n",
    "    return mat\n",
    "\n",
    "a = fill_sparse(a, sparsity)\n",
    "#b = fill_sparse(b, sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult = a.dot(b)\n",
    "mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33049e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67872651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_data(mat):\n",
    "    ellwidth = int(mat.shape[1]/2)\n",
    "    all_rows = []\n",
    "    all_idxs = []\n",
    "    all_nnzs = []\n",
    "    for row in range(mat.shape[0]):\n",
    "        rowdata = []\n",
    "        colidxs = []\n",
    "        all_nnzs.append(0)\n",
    "        for col in range(mat.shape[1]):\n",
    "            val = mat[row][col]\n",
    "            if val != 0:\n",
    "                rowdata.append(val)\n",
    "                colidxs.append(col)\n",
    "                all_nnzs[-1] += 1\n",
    "        rowdata = np.array(rowdata)\n",
    "        rowdata.resize(ellwidth)\n",
    "        all_rows.append(rowdata)\n",
    "        colidxs = np.array(colidxs)\n",
    "        colidxs.resize(ellwidth)\n",
    "        all_idxs.append(colidxs)\n",
    "    all_rows = np.array(all_rows).astype(np.float32).flatten()\n",
    "    all_idxs = np.array(all_idxs).astype(np.uint32).flatten()\n",
    "    all_nnzs = np.array(all_nnzs).astype(np.uint32)\n",
    "    return all_rows, all_idxs, all_nnzs, ellwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata, acols, annz, ellwa = to_data(a)\n",
    "adata, acols, annz, ellwa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb29574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acols = acols.astype(np.uint32)\n",
    "#annz = annz.astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata, acols, annz, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e741bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = cl.mem_flags\n",
    "adata_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=adata)\n",
    "acols_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=acols)\n",
    "annzs_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=annz)\n",
    "b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b)\n",
    "\n",
    "prg = cl.Program(ctx, \"\"\"\n",
    "// Every global_id_0 works on a row\n",
    "__kernel void SpMVNaive(__global  float* matData,     // INPUT MATRIX DATA\n",
    "                        __global  uint*  colIdx,\n",
    "                        __global  uint*  rowNnz,\n",
    "                        uint   ellwidth,\n",
    "                        __global  float* vector_x,    // INPUT\n",
    "                        __global  float* vector_y    // OUTPUT\n",
    "                        ) { // LOCAL SHARED BUFFER\n",
    "  uint gid = get_global_id(0);\n",
    "  \n",
    "  \n",
    "  uint nnz    = rowNnz[gid];\n",
    "  float sum = 0;\n",
    "  for (uint i = 0; i < nnz; i++) {\n",
    "    uint index   = gid * ellwidth + i;\n",
    "    uint col     = colIdx[index];\n",
    "    float aval  = matData[index];\n",
    "    float xval  = vector_x[col];\n",
    "    printf(\"aval, xval: %.2f,%.2f:%i-%i \\\\n\", aval, xval, col, index);\n",
    "    sum  += aval * xval;\n",
    "  }\n",
    "  printf(\"SUM/NNZ: %.2f %i \\\\n\", sum, nnz);\n",
    "  vector_y[gid] = sum;\n",
    "}\"\"\").build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c85bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(a.shape[0]).astype(np.float32)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72195ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ellw = np.array([ellwa]).astype(np.uint32)\n",
    "ellw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult = mult.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mult)*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7365fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_buf = cl.Buffer(ctx, mf.WRITE_ONLY, mult.nbytes)\n",
    "knl = prg.SpMVNaive  # Use this Kernel object for repeated calls\n",
    "knl(queue, [rows,], None, adata_buf, acols_buf, annzs_buf, ellw, b_buf, res_buf)\n",
    "\n",
    "res_np = np.empty_like(a)\n",
    "cl.enqueue_copy(queue, res, res_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6322f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(res-mult).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c100ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f76257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseTensor:\n",
    "    def __init__(self, dense_data, _children=(), _op=''):\n",
    "        data, idxs, nnzs, ellw = to_ell(dense_data)\n",
    "        self.data = data\n",
    "        self.idxs = idxs\n",
    "        self.nnzs = nnzs\n",
    "        self.ellw = ellw\n",
    "        self.shape = dense_data.shape\n",
    "        self.grad = 0\n",
    "        # internal variables used for autograd graph construction\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op # the op that produced this node, for graphviz / debugging / etc\n",
    "        \n",
    "        def _backward(in_grad=0.0):\n",
    "            self.grad = in_grad\n",
    "            return (in_grad,)\n",
    "        self._backward = _backward\n",
    "        \n",
    "\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, SparseTensor) else SparseTensor(other)\n",
    "        out = SparseTensor(self.data + other.data, (self, other), '+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "        out = Value(self.data**other, (self,), f'**{other}')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (other * self.data**(other-1)) * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def relu(self):\n",
    "        out = Value(0 if self.data < 0 else self.data, (self,), 'ReLU')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (out.data > 0) * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        # topological order all of the children in the graph\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        # go one variable at a time and apply the chain rule to get its gradient\n",
    "        self.grad = 1\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "\n",
    "    def __neg__(self): # -self\n",
    "        return self * -1\n",
    "\n",
    "    def __radd__(self, other): # other + self\n",
    "        return self + other\n",
    "\n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)\n",
    "\n",
    "    def __rsub__(self, other): # other - self\n",
    "        return other + (-self)\n",
    "\n",
    "    def __rmul__(self, other): # other * self\n",
    "        return self * other\n",
    "\n",
    "    def __truediv__(self, other): # self / other\n",
    "        return self * other**-1\n",
    "\n",
    "    def __rtruediv__(self, other): # other / self\n",
    "        return other * self**-1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data}, grad={self.grad})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "KERNEL_CODE = \"\"\"\n",
    "// Thread block size\n",
    "#define BLOCK_SIZE %(block_size)d\n",
    "// Matrix dimensions\n",
    "// (chosen as multiples of the thread block size for simplicity)\n",
    "#define WA %(w_a)d // Matrix A width\n",
    "#define HA %(h_a)d // Matrix A height\n",
    "#define WB %(w_b)d // Matrix B width\n",
    "#define HB WA  // Matrix B height\n",
    "#define WC WB  // Matrix C width\n",
    "#define HC HA  // Matrix C height\n",
    "/*\n",
    " * Copyright 1993-2009 NVIDIA Corporation.  All rights reserved.\n",
    " *\n",
    " * NVIDIA Corporation and its licensors retain all intellectual property and\n",
    " * proprietary rights in and to this software and related documentation.\n",
    " * Any use, reproduction, disclosure, or distribution of this software\n",
    " * and related documentation without an express license agreement from\n",
    " * NVIDIA Corporation is strictly prohibited.\n",
    " *\n",
    " * Please refer to the applicable NVIDIA end user license agreement (EULA)\n",
    " * associated with this source code for terms and conditions that govern\n",
    " * your use of this NVIDIA software.\n",
    " *\n",
    " */\n",
    "/* Matrix multiplication: C = A * B.\n",
    " * Device code.\n",
    " */\n",
    "#define AS(j, i) As[i + j * BLOCK_SIZE]\n",
    "#define BS(j, i) Bs[i + j * BLOCK_SIZE]\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "//! Matrix multiplication on the device: C = A * B\n",
    "//! WA is A's width and WB is B's width\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "__kernel __attribute__((reqd_work_group_size(16,16,1))) \n",
    "void\n",
    "matrixMul( __global float* C, __global float* A, __global float* B)\n",
    "{\n",
    "    __local float As[BLOCK_SIZE*BLOCK_SIZE];\n",
    "    __local float Bs[BLOCK_SIZE*BLOCK_SIZE];\n",
    "    // Block index\n",
    "    int bx = get_group_id(0);\n",
    "    int by = get_group_id(1);\n",
    "    // Thread index\n",
    "    int tx = get_local_id(0);\n",
    "    int ty = get_local_id(1);\n",
    "    // Index of the first sub-matrix of A processed by the block\n",
    "    int aBegin = WA * BLOCK_SIZE * by;\n",
    "    // Index of the last sub-matrix of A processed by the block\n",
    "    int aEnd   = aBegin + WA - 1;\n",
    "    // Step size used to iterate through the sub-matrices of A\n",
    "    int aStep  = BLOCK_SIZE;\n",
    "    // Index of the first sub-matrix of B processed by the block\n",
    "    int bBegin = BLOCK_SIZE * bx;\n",
    "    // Step size used to iterate through the sub-matrices of B\n",
    "    int bStep  = BLOCK_SIZE * WB;\n",
    "    // Csub is used to store the element of the block sub-matrix\n",
    "    // that is computed by the thread\n",
    "    float Csub = 0.0f;\n",
    "    // Loop over all the sub-matrices of A and B\n",
    "    // required to compute the block sub-matrix\n",
    "    for (int a = aBegin, b = bBegin;\n",
    "             a <= aEnd;\n",
    "             a += aStep, b += bStep) {\n",
    "        // Load the matrices from device memory\n",
    "        // to shared memory; each thread loads\n",
    "        // one element of each matrix\n",
    "        AS(ty, tx) = A[a + WA * ty + tx];\n",
    "        BS(ty, tx) = B[b + WB * ty + tx];\n",
    "        // Synchronize to make sure the matrices are loaded\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "        // Multiply the two matrices together;\n",
    "        // each thread computes one element\n",
    "        // of the block sub-matrix\n",
    "        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
    "            Csub += AS(ty, k) * BS(k, tx);\n",
    "        // Synchronize to make sure that the preceding\n",
    "        // computation is done before loading two new\n",
    "        // sub-matrices of A and B in the next iteration\n",
    "        barrier(CLK_LOCAL_MEM_FENCE);\n",
    "    }\n",
    "    // Write the block sub-matrix to device memory;\n",
    "    // each thread writes one element\n",
    "    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n",
    "}\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
